# Домашнее задание

Задания присылать на почту **ey.ml.course.hw@gmail.com** с темой "[HW 2 - Tree Models] Фамилия Имя"


Дедлайн: 14:00 28 января.
Если сделали задание, потом решили что-то доделать/исправить - новое письмо отправляйте в ту же цепочку писем (ответом на предыдущее)

Присылая задание - отправляйте ссылку на него в вашем репозитории на github.com и на всякий случай прикрепляйте файлы к письму.

Если не получается, просто прикрепляйте файлы к письму без ссылки на гитхаб.

## Задание 1 - Подбор параметров XGBoost

Требуется подобрать оптимальные параметры XGBoost 

Код для обучения и подбора параметров находится в TuneXGBoost.ipynb

Цель этого задания - понять смысл параметров, какие из них являются важными и попробовать понять, что качество модели при различных параметров говорит нам о структуре датасета. Такое понимание позволит с одной стороны, выбирать изначально неплохие параметры, зная структуру данных, а с другой стороны, использовать модели для лучшего понимания того, с какими данными и закономерностями мы работаем.

#### Обратите внимание на классы **GridSearchCV** и **RandomizedSearchCV** в sklearn


## Задание 2 - Написать свою реализацию градиентного бустинга

Вспомогательный код находится в SklearnDecisionTreeGB.ipynb

Требуется реализовать класс **SimpleGB** и оценить качество его работы

Автоматически генерируется коллекция для регрессии с линейной зависимостью (http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html)

И с нелинейной (http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_friedman1.html)

Также, в конце требуется подобрать хорошие параметры для реализованной вами модели.